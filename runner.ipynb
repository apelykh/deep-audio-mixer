{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import MixingModel\n",
    "from dataset import AudioMixingDataset\n",
    "from inference_utils import mix_song\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Torch version: ', torch.__version__)\n",
    "print('Device: ', device)\n",
    "\n",
    "print(torch.backends.cudnn.version())\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/media/apelykh/bottomless-pit/datasets/mixing/MUSDB18HQ'\n",
    "weights_dir = './weights'\n",
    "seed = 321\n",
    "chunk_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = AudioMixingDataset(os.path.join(base_path, 'train'),\n",
    "                             chunk_length=chunk_length, train_val_test_split=(0.95, 0.0, 0.0),\n",
    "                             mode='train', seed=seed)\n",
    "\n",
    "d_val = AudioMixingDataset(os.path.join(base_path, 'train'),\n",
    "                             chunk_length=chunk_length, train_val_test_split=(0.0, 0.05, 0.0),\n",
    "                             mode='val', seed=seed)\n",
    "\n",
    "d_test = AudioMixingDataset(os.path.join(base_path, 'test'),\n",
    "                             chunk_length=chunk_length, train_val_test_split=(0.0, 0.0, 1.0),\n",
    "                             mode='test', seed=seed)\n",
    "\n",
    "print('Train: {} tracks, {} chunks'.format(d_train.get_num_songs(), len(d_train)))\n",
    "print('Val: {} tracks, {} chunks'.format(d_val.get_num_songs(), len(d_val)))\n",
    "print('Test: {} tracks, {} chunks'.format(d_test.get_num_songs(), len(d_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "sample = d_val[10]\n",
    "# ipd.Audio(d[1103]['drums_audio'], rate=44100)\n",
    "\n",
    "print(sample['train_features'].shape)\n",
    "\n",
    "summed_spec = sample['train_features'].sum(axis=0)\n",
    "\n",
    "print(np.min(summed_spec), np.max(summed_spec))\n",
    "print(summed_spec)\n",
    "\n",
    "print(summed_spec.shape)\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "librosa.display.specshow(summed_spec)\n",
    "plt.title('Summed track spectrograms')\n",
    "\n",
    "print(np.min(sample['gt_features']), np.max(sample['gt_features']))\n",
    "print(sample['gt_features'])\n",
    "\n",
    "print(sample['gt_features'].shape)\n",
    "ax2 = plt.subplot(2,1,2, sharex=ax1)\n",
    "librosa.display.specshow(sample['gt_features'])\n",
    "plt.title('Mixture spectrogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(d)):\n",
    "    print('CHUNK: {}'.format(i))\n",
    "    print('---------------')\n",
    "    sample = d[i]\n",
    "    if i == 20:\n",
    "#         print(sample['drums_feature'].shape)\n",
    "#         librosa.display.specshow(sample['mixture_feature'])\n",
    "        ipd.Audio(sample['drums_audio'], rate=44100)\n",
    "        print('---------------')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(d_train, batch_size=32, shuffle=False,\n",
    "                          num_workers=0, collate_fn=None,\n",
    "                          pin_memory=False, drop_last=False, timeout=0,\n",
    "                          worker_init_fn=None)\n",
    "\n",
    "val_loader = DataLoader(d_val, batch_size=136, shuffle=False,\n",
    "                        num_workers=0, collate_fn=None,\n",
    "                        pin_memory=False, drop_last=False, timeout=0,\n",
    "                        worker_init_fn=None)\n",
    "\n",
    "test_loader = DataLoader(d_test, batch_size=32, shuffle=False,\n",
    "                        num_workers=0, collate_fn=None,\n",
    "                        pin_memory=False, drop_last=False, timeout=0,\n",
    "                        worker_init_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_loader:\n",
    "    print(batch['gt_features'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Defining and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixingModel().to(device)\n",
    "\n",
    "num_trainable_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('{} trainable parameters'.format(num_trainable_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = './weights/mixmodel_bs136_0020_3.346.pt'\n",
    "model.load_state_dict(torch.load(weights, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(start_epoch, num_epochs):\n",
    "    loss_hist = []\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            masked, masks = model(batch['train_features'].to(device))\n",
    "    #         print(masked.shape)\n",
    "    #         print(masks[0][0].shape)\n",
    "    #         print(masks[0])\n",
    "    #         masked_np = masked[0].detach().numpy()\n",
    "    #         librosa.display.specshow(masked_np)\n",
    "\n",
    "            loss = criterion(masked, batch['gt_features'].to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            each_n_batches = 1\n",
    "            if i % each_n_batches == each_n_batches - 1:\n",
    "                print('[%d, %4d] loss: %.3f' % (epoch + 1, i + 1, loss.item()))\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_epoch_loss = running_loss / len(val_loader)\n",
    "        print('Epoch {} loss: {}\\n'.format(epoch + 1, avg_epoch_loss))\n",
    "        loss_hist.append(avg_epoch_loss)\n",
    "    \n",
    "    return loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "num_epochs = 20\n",
    "loss_hist = train_model(start_epoch, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = os.path.join(weights_dir, 'mixmodel_bs{}_{:04d}_{:.3f}.pt'.format(136, 20, 3.346)) \n",
    "torch.save(model.state_dict(), weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(loss_hist, label='Train loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss');\n",
    "plt.xlim(0, 0 + 20)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('{}/loss.png'.format(weights_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = d_train[120]\n",
    "print('Song index: ', song['song_index'])\n",
    "print('Song name: ', song['song_name'])\n",
    "\n",
    "sum_audio = np.zeros_like(song['mixture_audio'])\n",
    "\n",
    "for track in d_test._tracklist:\n",
    "    if track != 'mixture':\n",
    "        sum_audio += song['{}_audio'.format(track)]\n",
    "\n",
    "ipd.Audio(sum_audio, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(song['mixture_audio'], rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.Tensor(song['train_features'][np.newaxis, :])\n",
    "masked, masks = model(features.to(device))\n",
    "\n",
    "res = masked.to('cpu').detach().numpy()\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Mixing the full song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_path = os.path.join(base_path, 'test/The Easton Ellises - Falcon 69')\n",
    "loaded_tracks = {}\n",
    "\n",
    "for track in d_train.get_tracklist():\n",
    "    track_path = os.path.join(song_path, '{}.wav'.format(track))\n",
    "    loaded_tracks[track], _ = librosa.load(track_path, sr=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "ipd.Audio(loaded_tracks['mixture'], rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summed tracks, no mix\n",
    "sum_audio = np.zeros_like(loaded_tracks['mixture'])\n",
    "\n",
    "for track in d_train.get_tracklist():\n",
    "    if track != 'mixture':\n",
    "        sum_audio += loaded_tracks['{}'.format(track)]\n",
    "\n",
    "ipd.Audio(sum_audio, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model result\n",
    "mixed_song = mix_song(d_train, model, loaded_tracks)\n",
    "ipd.Audio(mixed_song, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
